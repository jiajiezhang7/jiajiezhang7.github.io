<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Towards Safer Navigation - Reward Shaping with Prior Topographic Knowledge | Jiajie Zhang </title> <meta name="author" content="Jiajie Zhang"> <meta name="description" content="Enhancing navigation safety in deep reinforcement learning agents through reward shaping with prior map information"> <meta name="keywords" content="jiajie-zhang, mobile-robotics, embodied-ai, slam, navigation, lidar, ros, shanghaitech, mars-lab"> <meta property="og:site_name" content="Jiajie Zhang"> <meta property="og:type" content="website"> <meta property="og:title" content="Jiajie Zhang | Towards Safer Navigation - Reward Shaping with Prior Topographic Knowledge"> <meta property="og:url" content="https://jiajiezhang7-new.github.io/projects/4_deeplearning_project/"> <meta property="og:description" content="Enhancing navigation safety in deep reinforcement learning agents through reward shaping with prior map information"> <meta property="og:image" content="assets/img/prof_pic.jpg"> <meta property="og:locale" content="en"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="Towards Safer Navigation - Reward Shaping with Prior Topographic Knowledge"> <meta name="twitter:description" content="Enhancing navigation safety in deep reinforcement learning agents through reward shaping with prior map information"> <meta name="twitter:image" content="assets/img/prof_pic.jpg"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Jiajie Zhang"
        },
        "url": "https://jiajiezhang7-new.github.io/projects/4_deeplearning_project/",
        "@type": "WebSite",
        "description": "Enhancing navigation safety in deep reinforcement learning agents through reward shaping with prior map information",
        "headline": "Towards Safer Navigation - Reward Shaping with Prior Topographic Knowledge",
        
        "name": "Jiajie Zhang",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jiajiezhang7-new.github.io/projects/4_deeplearning_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Jiajie Zhang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Towards Safer Navigation - Reward Shaping with Prior Topographic Knowledge</h1> <p class="post-description">Enhancing navigation safety in deep reinforcement learning agents through reward shaping with prior map information</p> </header> <article> <h2 id="project-overview">Project Overview</h2> <p>This project addresses a critical challenge in deep reinforcement learning navigation: improving agent safety while maintaining navigation capabilities. Through innovative integration of prior map information into reward shaping, we successfully enhanced the safety distance between agents and obstacles, contributing to more reliable autonomous navigation systems.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/traditional_nav-480.webp 480w,/assets/img/traditional_nav-800.webp 800w,/assets/img/traditional_nav-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/traditional_nav.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Traditional Navigation Stack" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/rl_nav-480.webp 480w,/assets/img/rl_nav-800.webp 800w,/assets/img/rl_nav-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/rl_nav.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="RL Navigation Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Traditional navigation stack architecture; Right: Deep reinforcement learning navigation results </div> <h2 id="research-motivation">Research Motivation</h2> <p>The navigation field is dominated by two main approaches, each with distinct advantages and limitations:</p> <h3 id="1-traditional-navigation-stack">1. Traditional Navigation Stack</h3> <ul> <li> <strong>Advantages</strong>: Widely deployed in real-world applications, modular pipeline design</li> <li> <strong>Components</strong>: Mapping, localization, planning, and control modules</li> <li> <strong>Limitations</strong>: Requires extensive parameter tuning, limited generalization capability</li> </ul> <h3 id="2-reinforcement-learning-approach">2. Reinforcement Learning Approach</h3> <ul> <li> <strong>Advantages</strong>: End-to-end learning, potential for better generalization</li> <li> <strong>Limitations</strong>: Primarily validated in virtual environments, often generates unsafe navigation paths</li> <li> <strong>Challenge</strong>: High collision risk with obstacles due to lack of explicit safety constraints</li> </ul> <h2 id="technical-approach">Technical Approach</h2> <h3 id="network-architecture">Network Architecture</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/ppo_framework-480.webp 480w,/assets/img/ppo_framework-800.webp 800w,/assets/img/ppo_framework-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/ppo_framework.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="PPO Framework Architecture" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Proximal Policy Optimization (PPO) framework with multi-modal input processing </div> <h4 id="input-layer">Input Layer</h4> <ul> <li> <strong>RGB Images</strong>: 256×256×3 resolution for visual perception</li> <li> <strong>Depth Maps</strong>: 256×256×1 for spatial understanding</li> <li> <strong>GPS and Compass Data</strong>: 2D vector for global positioning</li> </ul> <h4 id="feature-extraction">Feature Extraction</h4> <ul> <li> <strong>RGB &amp; Depth Processing</strong>: Independent ResNet18 backbones for visual feature extraction</li> <li> <strong>GPS/Compass Processing</strong>: Two-layer MLP (2→32→512) for positional encoding</li> </ul> <h4 id="feature-fusion">Feature Fusion</h4> <ul> <li> <strong>Temporal Integration</strong>: Dual-layer LSTM (hidden_size=512)</li> <li> <strong>Multi-modal Fusion</strong>: Combines visual and positional information</li> </ul> <h4 id="output-layer">Output Layer</h4> <ul> <li> <strong>Actor Head</strong>: 4 discrete actions <ul> <li>Turn left/right 30°</li> <li>Move forward 0.5m</li> <li>Stop action</li> </ul> </li> <li> <strong>Critic Head</strong>: State value estimation for policy optimization</li> </ul> <h3 id="reward-shaping-strategy">Reward Shaping Strategy</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/method_overview-480.webp 480w,/assets/img/method_overview-800.webp 800w,/assets/img/method_overview-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/method_overview.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Method Overview" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/reward_shaping-480.webp 480w,/assets/img/reward_shaping-800.webp 800w,/assets/img/reward_shaping-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/reward_shaping.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reward Shaping Mechanism" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Overall method architecture; Right: Reward shaping mechanism with safety considerations </div> <h4 id="1-exploration-reward">1. Exploration Reward</h4> <ul> <li>Encourages exploration of unknown areas</li> <li>Based on goal distance changes to prevent local minima</li> <li>Prevents overly cautious behavior that impedes progress</li> </ul> <h4 id="2-safety-reward">2. Safety Reward</h4> <ul> <li> <strong>Penalty Zone</strong>: Negative reward for distances &lt; 0.5m from obstacles</li> <li> <strong>Safety Zone</strong>: Positive reward for distances between 0.5-2m</li> <li> <strong>Optimal Zone</strong>: Maximum reward for maintaining safe navigation distances</li> </ul> <h2 id="experimental-setup">Experimental Setup</h2> <h3 id="environment-and-datasets">Environment and Datasets</h3> <ul> <li> <strong>Simulation Platform</strong>: Habitat Simulator for photorealistic environments</li> <li> <strong>Training Datasets</strong>: MP3D (Matterport3D) and Gibson datasets</li> <li> <strong>Environment Diversity</strong>: Various indoor layouts and obstacle configurations</li> </ul> <h3 id="training-configuration">Training Configuration</h3> <ul> <li> <strong>Parallel Environments</strong>: 4 simultaneous training environments</li> <li> <strong>Training Steps</strong>: 5 million steps for convergence</li> <li> <strong>Training Duration</strong>: Approximately 10 hours</li> <li> <strong>Hardware</strong>: RTX 3060 (12GB VRAM)</li> </ul> <h2 id="evaluation-metrics">Evaluation Metrics</h2> <h3 id="1-success-rate">1. Success Rate</h3> <ul> <li> <strong>Definition</strong>: Goal reached within 500 steps</li> <li> <strong>Success Threshold</strong>: Within 0.2m of target location</li> <li> <strong>Measurement</strong>: Percentage of successful navigation episodes</li> </ul> <h3 id="2-spl-success-weighted-by-path-length">2. SPL (Success weighted by Path Length)</h3> <ul> <li> <strong>Formula</strong>: SPL = (1/N) × Σ(Si × li/max(pi, li))</li> <li> <strong>Purpose</strong>: Combined measure of success rate and path efficiency</li> <li> <strong>Advantage</strong>: Penalizes inefficient paths even if successful</li> </ul> <h3 id="3-path-safety-custom-metric">3. Path Safety (Custom Metric)</h3> <ul> <li> <strong>Definition</strong>: Average distance to nearest obstacles throughout trajectory</li> <li> <strong>Innovation</strong>: Novel metric specifically designed for safety evaluation</li> <li> <strong>Importance</strong>: Quantifies navigation safety beyond binary success/failure</li> </ul> <h2 id="results-and-analysis">Results and Analysis</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/navigation_results-480.webp 480w,/assets/img/navigation_results-800.webp 800w,/assets/img/navigation_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/navigation_results.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Navigation Performance Results" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/performance_analysis-480.webp 480w,/assets/img/performance_analysis-800.webp 800w,/assets/img/performance_analysis-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/performance_analysis.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Performance Analysis" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Left: Quantitative navigation results; Right: Detailed performance analysis across different metrics </div> <h3 id="safety-improvements">Safety Improvements</h3> <ul> <li> <strong>RGBD Agent</strong>: Achieved 5.75cm increase in average safety distance</li> <li> <strong>Overall Safety</strong>: 1.64% improvement in path safety metric</li> <li> <strong>Collision Reduction</strong>: Significant decrease in near-collision events</li> </ul> <h3 id="sensor-impact-analysis">Sensor Impact Analysis</h3> <ul> <li> <strong>Depth Sensing</strong>: Crucial for effective safety distance mapping</li> <li> <strong>RGB-only Input</strong>: Insufficient for reliable obstacle distance estimation</li> <li> <strong>Multi-modal Advantage</strong>: Combined RGB-D input provides optimal performance</li> </ul> <h2 id="technology-stack">Technology Stack</h2> <ul> <li> <strong>Deep Learning Framework</strong>: PyTorch 1.9+</li> <li> <strong>RL Algorithm</strong>: Proximal Policy Optimization (PPO)</li> <li> <strong>Simulation</strong>: Habitat-Sim, Habitat-Lab</li> <li> <strong>Computer Vision</strong>: OpenCV, PIL</li> <li> <strong>Neural Networks</strong>: ResNet18, LSTM</li> <li> <strong>Environment</strong>: Python 3.8+, CUDA 11.2</li> <li> <strong>Visualization</strong>: Matplotlib, TensorBoard</li> </ul> <h2 id="performance-metrics">Performance Metrics</h2> <h3 id="training-performance">Training Performance</h3> <ul> <li> <strong>Convergence Time</strong>: 5M steps (≈10 hours)</li> <li> <strong>Sample Efficiency</strong>: Improved over baseline methods</li> <li> <strong>Stability</strong>: Consistent performance across multiple runs</li> </ul> <h3 id="navigation-quality">Navigation Quality</h3> <ul> <li> <strong>Success Rate</strong>: Competitive with state-of-the-art methods</li> <li> <strong>Path Efficiency</strong>: Maintained while improving safety</li> <li> <strong>Safety Distance</strong>: Significant improvement over baseline</li> </ul> <h2 id="future-work">Future Work</h2> <h3 id="short-term-goals">Short-term Goals</h3> <ol> <li> <strong>Extended Training</strong>: Scale to 75 million steps for better convergence</li> <li> <strong>Reward Optimization</strong>: Fine-tune reward function parameters</li> <li> <strong>Sensor Fusion</strong>: Explore additional sensor modalities</li> </ol> <h3 id="long-term-vision">Long-term Vision</h3> <ol> <li> <strong>Real Robot Validation</strong>: Deploy on physical robotic platforms</li> <li> <strong>Multi-agent Systems</strong>: Extend to collaborative navigation scenarios</li> <li> <strong>Dynamic Environments</strong>: Handle moving obstacles and changing layouts</li> <li> <strong>Transfer Learning</strong>: Adapt to new environments with minimal retraining</li> </ol> <h2 id="project-impact">Project Impact</h2> <p>This research contributes to the field of safe autonomous navigation by:</p> <ul> <li>Demonstrating effective integration of prior knowledge in RL</li> <li>Providing a novel safety-aware reward shaping approach</li> <li>Establishing new evaluation metrics for navigation safety</li> <li>Bridging the gap between simulation and real-world deployment</li> </ul> <h2 id="project-team">Project Team</h2> <ul> <li> <strong>Lead Researcher</strong>: Jiajie Zhang (zhangjj2023@shanghaitech.edu.cn)</li> <li> <strong>Advisor</strong>: Professor Soeren Schwertfeger</li> <li> <strong>Institution</strong>: MARS Lab, ShanghaiTech University</li> </ul> <h2 id="related-resources">Related Resources</h2> <ul> <li> <strong>Project Slides</strong>: <a href="../files/CS280_DL_Project_Defence.pdf">Deep Learning Project Defense</a> </li> <li> <strong>Technical Report</strong>: <a href="../files/DeepLearing_Project_Report.pdf">Detailed Project Report</a> </li> <li> <strong>Code Repository</strong>: <a href="https://github.com/jiajiezhang7/safe_rl_navigation" rel="external nofollow noopener" target="_blank">GitHub Repository</a> </li> </ul> <hr> <p><em>This project represents a significant step towards developing safer autonomous navigation systems through the integration of deep reinforcement learning and safety-aware reward design.</em></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Jiajie Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>